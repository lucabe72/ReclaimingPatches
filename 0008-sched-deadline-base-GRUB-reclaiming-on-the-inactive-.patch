From 8174b435ae6603e5b58ae00606248b5a9755581c Mon Sep 17 00:00:00 2001
From: Luca Abeni <lucabe72@gmail.com>
Date: Fri, 6 Jan 2017 23:07:29 +0100
Subject: [PATCH 8/9] sched/deadline: base GRUB reclaiming on the inactive
 utilization

Instead of decreasing the runtime as "dq = -Uact dt" (eventually
divided by the maximum utilization available for deadline tasks),
decrease it as "dq = -(1 - Uinact) dt", where Uinact is the "inactive
utilization".
In this way, the maximum fraction of CPU time that can be reclaimed
is given by the total utilization of deadline tasks.
This approach solves some fairness issues that have been noticed with
"traditional" global GRUB reclaiming.

Signed-off-by: luca abeni <luca.abeni@santannapisa.it>
---
 kernel/sched/core.c     |  4 ----
 kernel/sched/deadline.c | 27 ++++++++++++++++-----------
 kernel/sched/sched.h    |  6 ------
 3 files changed, 16 insertions(+), 21 deletions(-)

diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 844e1e2..327699c 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -8289,10 +8289,6 @@ static void sched_dl_do_global(void)
 		raw_spin_unlock_irqrestore(&dl_b->lock, flags);
 
 		rcu_read_unlock_sched();
-		if (dl_b->bw == -1)
-			cpu_rq(cpu)->dl.deadline_bw_inv = 1 << 8;
-		else
-			cpu_rq(cpu)->dl.deadline_bw_inv = to_ratio(global_rt_runtime(), global_rt_period()) >> 12;
 	}
 }
 
diff --git a/kernel/sched/deadline.c b/kernel/sched/deadline.c
index 0d97480..5440c5d 100644
--- a/kernel/sched/deadline.c
+++ b/kernel/sched/deadline.c
@@ -220,10 +220,6 @@ void init_dl_rq(struct dl_rq *dl_rq)
 #else
 	init_dl_bw(&dl_rq->dl_bw);
 #endif
-	if (global_rt_runtime() == RUNTIME_INF)
-		dl_rq->deadline_bw_inv = 1 << 8;
-	else
-		dl_rq->deadline_bw_inv = to_ratio(global_rt_runtime(), global_rt_period()) >> 12;
 }
 
 #ifdef CONFIG_SMP
@@ -839,14 +835,23 @@ extern bool sched_rt_bandwidth_account(struct rt_rq *rt_rq);
 /*
  * This function implements the GRUB accounting rule:
  * according to the GRUB reclaiming algorithm, the runtime is
- * not decreased as "dq = -dt", but as "dq = -Uact dt", where
- * Uact is the (per-runqueue) active utilization.
- * Since rq->dl.running_bw contains Uact * 2^20, the result
- * has to be shifted right by 20.
+ * not decreased as "dq = -dt", but as "dq = (1 - Uinact) dt", where
+ * Uinact is the (per-runqueue) inactive utilization, computed as the
+ * difference between the "total runqueue utilization" and the runqueue
+ * active utilization.
+ * Since rq->dl.running_bw and rq->dl.this_bw contain utilizations
+ * multiplied by 2^20, the result has to be shifted right by 20.
  */
-u64 grub_reclaim(u64 delta, struct rq *rq)
+u64 grub_reclaim(u64 delta, struct rq *rq, u64 u)
 {
-	return (delta * rq->dl.running_bw * rq->dl.deadline_bw_inv) >> 20 >> 8;
+	u64 u_act;
+
+	if (rq->dl.this_bw - rq->dl.running_bw > (1 << 20) - u)
+		u_act = u;
+	else
+		u_act = (1 << 20) - rq->dl.this_bw + rq->dl.running_bw;
+
+	return (delta * u_act) >> 20;
 }
 
 /*
@@ -892,7 +897,7 @@ static void update_curr_dl(struct rq *rq)
 	sched_rt_avg_update(rq, delta_exec);
 
 	if (unlikely(dl_se->flags & SCHED_FLAG_RECLAIM))
-		delta_exec = grub_reclaim(delta_exec, rq);
+		delta_exec = grub_reclaim(delta_exec, rq, curr->dl.dl_bw);
 	dl_se->runtime -= delta_exec;
 
 throttle:
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 28464aa..dc06c48 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -553,12 +553,6 @@ struct dl_rq {
 	 * runqueue (inactive utilization = this_bw - running_bw).
 	 */
 	u64 this_bw;
-
-	/*
-	 * Inverse of the fraction of CPU utilization that can be reclaimed
-	 * by the GRUB algorithm.
-	 */
-	u64 deadline_bw_inv;
 };
 
 #ifdef CONFIG_SMP
-- 
2.7.4

